{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Winning Jeopardy\n",
    "\n",
    "Jeopardy is a popular TV show in the US where participants answer questions to win money. It's been running for a few decades, and is a major force in popular culture.\n",
    "\n",
    "Let's say we want to compete on Jeopardy, and you're looking for any edge we can get to win. In this project, we will work with a dataset of Jeopardy questions to figure out some patterns in the questions that could help us win.\n",
    "\n",
    "## Define our hypothesis\n",
    "\n",
    "Before we start the analysis, lets define our null and alternate hypothesis\n",
    "\n",
    "   - null hypothesis - we cannot predict questions based on past questions. any relationship between questions asked in the newer episodes to question asked in the past episodes are just random occurences\n",
    "   - alternate hypothesis - There is a strong relationship between newer questions to those asked in the older episode. By analysing newer questions against older questions, we can recognize a pattern, thereby enabling us to predict questions better\n",
    "\n",
    "### Read data and do basic exploration\n",
    "\n",
    "The dataset is named jeopardy.csv, and contains 20000 rows from the beginning of a full dataset of Jeopardy questions, which you can download [here](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file).\n",
    "\n",
    "Lets start off by reading the dataset and creating pandas dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size = (19999, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "jeopardy = pd.read_csv(\"jeopardy.csv\")\n",
    "\n",
    "print(\"dataset size = {}\".format(jeopardy.shape))\n",
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, each row in the dataset represents a single question on a single episode of Jeopardy. Here are explanations of each column:\n",
    "\n",
    "  - **`Show Number`** -- the Jeopardy episode number of the show this question was in.\n",
    "  - **`Air Date`** -- the date the episode aired.\n",
    "  - **`Round`** -- the round of Jeopardy that the question was asked in. Jeopardy has several rounds as each episode progresses.\n",
    "  - **`Category`** -- the category of the question.\n",
    "  - **`Value`** -- the number of dollars answering the question correctly is worth.\n",
    "  - **`Question`** -- the text of the question.\n",
    "  - **`Answer`** -- the text of the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
       "       ' Question', ' Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some of the columns seems to have leading spaces. Lets fix it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy.columns = map(str.strip, ['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
    "       ' Question', ' Answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question',\n",
       "       'Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all column's extra leading spaces have been stripped\n",
    "\n",
    "## Data normalization\n",
    "\n",
    "Before we go any further, we want to ensure the the colunn text and values are normalized, ie, we want to make the comparable. We can do this by\n",
    "\n",
    "   - for both **`Question`** and **`Answer`**\n",
    "       - removing puctuations\n",
    "       - converting text to lower case\n",
    "   - The **`Value`** column should also be numeric, to allow you to manipulate it more easily. You'll need to remove the dollar sign from the beginning of each value and convert the column from text to numeric.\n",
    "   - The **`Air Date`** column should also be a datetime, not a string, to enable you to work with it more easi\n",
    "   \n",
    "To accomplish the above, we will write couple of helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"[^A-Za-z0-9\\s]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "def normalize_values(text):\n",
    "    text = re.sub(\"[^A-Za-z0-9\\s]\", \"\", text)\n",
    "    try:\n",
    "        text = int(text)\n",
    "    except Exception:\n",
    "        text = 0\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy[\"clean_question\"] = jeopardy[\"Question\"].apply(normalize_text)\n",
    "jeopardy[\"clean_answer\"] = jeopardy[\"Answer\"].apply(normalize_text)\n",
    "jeopardy[\"clean_value\"] = jeopardy[\"Value\"].apply(normalize_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>clean_question</th>\n",
       "      <th>clean_answer</th>\n",
       "      <th>clean_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "      <td>for the last 8 years of his life galileo was u...</td>\n",
       "      <td>copernicus</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "      <td>no 2 1912 olympian football star at carlisle i...</td>\n",
       "      <td>jim thorpe</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>the city of yuma in this state has a record av...</td>\n",
       "      <td>arizona</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>in 1963 live on the art linkletter show this c...</td>\n",
       "      <td>mcdonalds</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "      <td>signer of the dec of indep framer of the const...</td>\n",
       "      <td>john adams</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY  $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES  $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...  $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE  $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES  $200   \n",
       "\n",
       "                                            Question      Answer  \\\n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus   \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe   \n",
       "2  The city of Yuma in this state has a record av...     Arizona   \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's   \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams   \n",
       "\n",
       "                                      clean_question clean_answer  clean_value  \n",
       "0  for the last 8 years of his life galileo was u...   copernicus          200  \n",
       "1  no 2 1912 olympian football star at carlisle i...   jim thorpe          200  \n",
       "2  the city of yuma in this state has a record av...      arizona          200  \n",
       "3  in 1963 live on the art linkletter show this c...    mcdonalds          200  \n",
       "4  signer of the dec of indep framer of the const...   john adams          200  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy[\"clean_value\"].value_counts(dropna=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy[\"Value\"].value_counts(dropna=False)[\"None\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have 336 rows with value as zero and they correspond to rows which has value \"None\" in the original columns. So we are good to go\n",
    "\n",
    "Now lets concentrate on the **`Air Date`** which should be datetime column and not string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy[\"Air Date\"] = pd.to_datetime(jeopardy[\"Air Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Show Number                int64\n",
       "Air Date          datetime64[ns]\n",
       "Round                     object\n",
       "Category                  object\n",
       "Value                     object\n",
       "Question                  object\n",
       "Answer                    object\n",
       "clean_question            object\n",
       "clean_answer              object\n",
       "clean_value                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>clean_question</th>\n",
       "      <th>clean_answer</th>\n",
       "      <th>clean_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "      <td>for the last 8 years of his life galileo was u...</td>\n",
       "      <td>copernicus</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "      <td>no 2 1912 olympian football star at carlisle i...</td>\n",
       "      <td>jim thorpe</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>the city of yuma in this state has a record av...</td>\n",
       "      <td>arizona</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>in 1963 live on the art linkletter show this c...</td>\n",
       "      <td>mcdonalds</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "      <td>signer of the dec of indep framer of the const...</td>\n",
       "      <td>john adams</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number   Air Date      Round                         Category Value  \\\n",
       "0         4680 2004-12-31  Jeopardy!                          HISTORY  $200   \n",
       "1         4680 2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES  $200   \n",
       "2         4680 2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...  $200   \n",
       "3         4680 2004-12-31  Jeopardy!                 THE COMPANY LINE  $200   \n",
       "4         4680 2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES  $200   \n",
       "\n",
       "                                            Question      Answer  \\\n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus   \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe   \n",
       "2  The city of Yuma in this state has a record av...     Arizona   \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's   \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams   \n",
       "\n",
       "                                      clean_question clean_answer  clean_value  \n",
       "0  for the last 8 years of his life galileo was u...   copernicus          200  \n",
       "1  no 2 1912 olympian football star at carlisle i...   jim thorpe          200  \n",
       "2  the city of yuma in this state has a record av...      arizona          200  \n",
       "3  in 1963 live on the art linkletter show this c...    mcdonalds          200  \n",
       "4  signer of the dec of indep framer of the const...   john adams          200  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So looks like all our value transformation has been successful. We can now move on to analyzing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of past questions\n",
    "\n",
    "### do the questions contain the answers themselves?\n",
    "\n",
    "In order to figure out whether to study past questions, study general knowledge, or not study it all, it would be helpful to figure out two things:\n",
    "\n",
    "   - How often the answer is deducible from the question.\n",
    "   - How often new questions are repeats of older questions.\n",
    "\n",
    "We can answer the second question by seeing how often complex words (> 6 characters) reoccur. We can answer the first question by seeing how many times words in the answer also occur in the question. We'll work on the first question now, and come back to the second.\n",
    "\n",
    "We will build a function which will \n",
    "   - split both question and answer\n",
    "   - remove 'the' from answer as it is not useful to match\n",
    "   - count the number of times the words in answer apperar in question\n",
    "   \n",
    "We can run this function on all rows and save the answer in a separate column. That will provide us insight about how many words in answer is available in question itself\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_matches(row):\n",
    "    split_answer = row[\"clean_answer\"].split(\" \")\n",
    "    split_question = row[\"clean_question\"].split(\" \")\n",
    "    if \"the\" in split_answer:\n",
    "        split_answer.remove(\"the\")\n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    match_count = 0\n",
    "    for item in split_answer:\n",
    "        if item in split_question:\n",
    "            match_count += 1\n",
    "    return match_count / len(split_answer)\n",
    "\n",
    "jeopardy[\"answer_in_question\"] = jeopardy.apply(count_matches, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer in question = 6.05% \n"
     ]
    }
   ],
   "source": [
    "print(\"Answer in question = {0:.2f}% \".format(jeopardy[\"answer_in_question\"].mean() * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only about 6% of the time answers are contained in the question itself. This isn't  much and difficult to depend on and we cannot answer question just by hearing the question carefully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### do questions repeat often? if yes, how often?\n",
    "\n",
    "Let's say we want to investigate how often new questions are repeats of older ones. Unfortuantely we cannot completey  answer this questions as we only have small subset of all Jeopardy questions ever asked in the show. Our dataset is around 10% of the full question set, but we can use it as a sample representative and try to get some insight out of what we have\n",
    "\n",
    "to answer this question, we can follow this algorithm\n",
    "\n",
    "   - Sort **`jeopardy`** in order of ascending air date. - This way we can pick up a question and look for all previous questions based on air date column\n",
    "   - Maintain a set called **`terms_used`** that will be empty initially.\n",
    "   - Iterate through each row of jeopardy.\n",
    "   - Split **`clean_question`** into words, remove any word shorter than 6 characters, and check if each word occurs in **`terms_used`**.\n",
    "       - If it does, increment a counter.\n",
    "       - Add each word to **`terms_used`**.\n",
    "       \n",
    "This will enable you to check if the terms in questions have been used previously or not. Only looking at words greater than 6 characters enables you to filter out words like the and than, which are commonly used, but don't tell you a lot about a question.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question overlap = 68.76% \n"
     ]
    }
   ],
   "source": [
    "# set to store all the terms/words used in questions\n",
    "terms_used = []\n",
    "terms_used_unique = []\n",
    "\n",
    "\n",
    "def find_mean_question_overlap(jeopardy):\n",
    "    question_overlap = []\n",
    "    jeopardy = jeopardy.sort_values(\"Air Date\")\n",
    "\n",
    "    for i, row in jeopardy.iterrows():\n",
    "        split_question = row[\"clean_question\"].split(\" \")\n",
    "        split_question = [q for q in split_question if len(q) > 5]\n",
    "        match_count = 0\n",
    "        for word in split_question:\n",
    "            if word in terms_used:\n",
    "                match_count += 1\n",
    "        for word in split_question:\n",
    "            terms_used.append(word)\n",
    "        if len(split_question) > 0:\n",
    "            match_count /= len(split_question)\n",
    "        question_overlap.append(match_count)\n",
    "    jeopardy[\"question_overlap\"] = question_overlap\n",
    "    terms_used_unique = list(set(terms_used))\n",
    "    return jeopardy[\"question_overlap\"].mean()\n",
    "\n",
    "overlap_mean = find_mean_question_overlap(jeopardy)\n",
    "print(\"Question overlap = {0:.2f}% \".format(overlap_mean * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hrefhttpwwwjarchivecommedia20110718j10jpg',\n",
       " 'consistent',\n",
       " 'leinart',\n",
       " 'evertuned',\n",
       " 'shopkeepers',\n",
       " 'impoverished',\n",
       " 'csonkaa',\n",
       " 'easing',\n",
       " 'mercurys',\n",
       " 'typical',\n",
       " 'socially',\n",
       " 'misnamed',\n",
       " 'courtney',\n",
       " 'amount',\n",
       " 'jazair',\n",
       " 'boutiques',\n",
       " 'pianoplaying',\n",
       " 'benson',\n",
       " 'refused',\n",
       " 'associations',\n",
       " 'footwear',\n",
       " 'sentinels',\n",
       " 'hrefhttpwwwjarchivecommedia20100319dj26jpg',\n",
       " 'following',\n",
       " 'fingershaped',\n",
       " 'langera',\n",
       " 'soulsia',\n",
       " 'coeducational',\n",
       " '54yearold',\n",
       " 'saxons',\n",
       " 'kellya',\n",
       " 'interracial',\n",
       " 'favors',\n",
       " 'antiperspirant',\n",
       " 'ibadan',\n",
       " 'elements',\n",
       " 'frenchman',\n",
       " 'jellyfish',\n",
       " 'fledgling',\n",
       " 'exalted',\n",
       " 'porters',\n",
       " 'bribed',\n",
       " 'approving',\n",
       " 'drowned',\n",
       " 'mazarin',\n",
       " 'targetblankcharles',\n",
       " 'indiana',\n",
       " 'fighter',\n",
       " 'twinkle',\n",
       " 'bottoms',\n",
       " 'gigolo',\n",
       " 'purify',\n",
       " 'hrefhttpwwwjarchivecommedia20111103dj14jpg',\n",
       " 'friday',\n",
       " 'battles',\n",
       " 'action',\n",
       " 'drunkenness',\n",
       " 'dwellings',\n",
       " 'eliminated',\n",
       " 'phoenix',\n",
       " 'devitos',\n",
       " 'altitudes',\n",
       " 'hopalong',\n",
       " 'promontory',\n",
       " 'sleeket',\n",
       " 'nowsmallest',\n",
       " 'aucklandarea',\n",
       " 'scarlett',\n",
       " 'lombardys',\n",
       " 'pfounded',\n",
       " 'furnace',\n",
       " 'inanimate',\n",
       " 'nearby',\n",
       " 'majorelle',\n",
       " 'fringe',\n",
       " 'parlor',\n",
       " 'collyer',\n",
       " 'escudos',\n",
       " 'cloudy',\n",
       " 'seaworthy',\n",
       " 'bequest',\n",
       " 'auditioned',\n",
       " 'bogota',\n",
       " 'donnelly',\n",
       " 'susann',\n",
       " 'neologisms',\n",
       " 'protruding',\n",
       " 'manzarek',\n",
       " 'griqualand',\n",
       " 'validate',\n",
       " 'reuters',\n",
       " 'hrefhttpwwwjarchivecommedia20081222j30jpg',\n",
       " 'strict',\n",
       " 'shuffling',\n",
       " 'beavis',\n",
       " 'devout',\n",
       " 'featurea',\n",
       " 'russet',\n",
       " 'residents',\n",
       " 'darkness',\n",
       " 'gandolfo',\n",
       " 'impediments',\n",
       " 'endowment',\n",
       " 'taylors',\n",
       " 'synthpop',\n",
       " 'ringer',\n",
       " 'maidens',\n",
       " 'intoned',\n",
       " 'acquisitions',\n",
       " 'busting',\n",
       " 'dingdong',\n",
       " 'hrefhttpwwwjarchivecommedia20020702dj07jpg',\n",
       " 'furlined',\n",
       " 'lacked',\n",
       " 'sonnet',\n",
       " 'resistance',\n",
       " 'quarterbacks',\n",
       " 'tackle',\n",
       " 'beetles',\n",
       " 'offseason',\n",
       " 'dilute',\n",
       " 'lapidate',\n",
       " 'koprulu',\n",
       " 'buffalo',\n",
       " 'refurbished',\n",
       " 'winglike',\n",
       " 'elderly',\n",
       " 'fasola',\n",
       " 'california',\n",
       " 'control',\n",
       " 'strutting',\n",
       " 'palette',\n",
       " 'havanas',\n",
       " 'clever',\n",
       " 'condensation',\n",
       " 'chorus',\n",
       " 'frequent',\n",
       " 'inhabit',\n",
       " 'courtship',\n",
       " 'crassus',\n",
       " 'fullfigured',\n",
       " 'leaning',\n",
       " 'hardwood',\n",
       " 'talkshow',\n",
       " 'hrefhttpwwwjarchivecommedia20060426j02mp3thisa',\n",
       " 'weavers',\n",
       " 'pharaoh',\n",
       " 'zacatecas',\n",
       " 'spanishamerican',\n",
       " 'taxation',\n",
       " 'frenzied',\n",
       " 'square',\n",
       " 'pledge',\n",
       " 'mincemeat',\n",
       " 'foremost',\n",
       " 'solidarity',\n",
       " 'hrefhttpwwwjarchivecommedia20110330dj28jpg',\n",
       " 'pyramus',\n",
       " 'dirigible',\n",
       " 'cassia',\n",
       " 'distributors',\n",
       " 'resemble',\n",
       " 'sophoclean',\n",
       " 'bazaar',\n",
       " 'critters',\n",
       " 'chiller',\n",
       " 'rainfall',\n",
       " 'zingers',\n",
       " 'flosshilde',\n",
       " 'senates',\n",
       " 'passionate',\n",
       " 'hrefhttpwwwjarchivecommedia20100621j10wmvalex',\n",
       " 'klaproth',\n",
       " 'himnusz',\n",
       " 'silvery',\n",
       " 'invigorate',\n",
       " 'arafat',\n",
       " 'contribution',\n",
       " 'supplyside',\n",
       " 'snatched',\n",
       " 'maneuvers',\n",
       " 'fatimid',\n",
       " 'mischiefmaker',\n",
       " 'arresting',\n",
       " 'tragic',\n",
       " 'accompany',\n",
       " 'lecturer',\n",
       " 'possum',\n",
       " 'rockabilly',\n",
       " 'teatro',\n",
       " 'syncopated',\n",
       " 'hrefhttpwwwjarchivecommedia20061226dj16jpg',\n",
       " 'amendments',\n",
       " 'prosperous',\n",
       " 'faithfullyi',\n",
       " 'microorganism',\n",
       " 'triangular',\n",
       " 'jumped',\n",
       " 'equatorial',\n",
       " 'daydream',\n",
       " 'chestnut',\n",
       " 'gallagher',\n",
       " 'subaru',\n",
       " 'travel',\n",
       " 'izathuraia',\n",
       " 'annmargret',\n",
       " 'coinage',\n",
       " 'gastineau',\n",
       " 'boiling',\n",
       " 'afghan',\n",
       " 'centimos',\n",
       " 'hellman',\n",
       " 'drillbit',\n",
       " 'banquo',\n",
       " 'hrefhttpwwwjarchivecommedia20060329dj26jpg',\n",
       " 'boothia',\n",
       " 'isosceles',\n",
       " 'temblor',\n",
       " 'lawful',\n",
       " 'blowgun',\n",
       " 'pavarottis',\n",
       " 'beaches',\n",
       " 'madras',\n",
       " 'brownlow',\n",
       " 'baldric',\n",
       " 'transplants',\n",
       " 'bullet',\n",
       " 'sensual',\n",
       " 'earned',\n",
       " 'xstatic',\n",
       " 'chiang',\n",
       " 'unfinished',\n",
       " 'cliche',\n",
       " 'potala',\n",
       " 'architecture',\n",
       " 'authored',\n",
       " 'gregorian',\n",
       " 'wisest',\n",
       " 'cuervo',\n",
       " 'oneounce',\n",
       " 'yippie',\n",
       " 'zucchero',\n",
       " 'arthritic',\n",
       " 'descend',\n",
       " 'zodiacs',\n",
       " 'reknown',\n",
       " 'wolfdog',\n",
       " 'fishing',\n",
       " 'martins',\n",
       " 'removed',\n",
       " 'carriage',\n",
       " 'targetblankthis',\n",
       " 'yohoho',\n",
       " 'attack',\n",
       " 'postulated',\n",
       " 'huckleberry',\n",
       " 'hrefhttpwwwjarchivecommedia20050629j10cjpg',\n",
       " 'spears',\n",
       " 'soldiers',\n",
       " 'luxury',\n",
       " 'secondleading',\n",
       " 'postshower',\n",
       " 'lingerie',\n",
       " 'abounding',\n",
       " 'utopia',\n",
       " 'steamships',\n",
       " '4syllable',\n",
       " 'portugal',\n",
       " 'enlightenment',\n",
       " 'burglars',\n",
       " 'tinkers',\n",
       " 'oxymoron',\n",
       " 'sullivans',\n",
       " 'hrefhttpwwwjarchivecommedia20100621j06wmvalex',\n",
       " 'vibrating',\n",
       " 'matching',\n",
       " 'prohibition',\n",
       " 'owners',\n",
       " 'halfghost',\n",
       " 'reykjanes',\n",
       " 'matter',\n",
       " 'chutes',\n",
       " 'stranger',\n",
       " 'stealth',\n",
       " 'eleven',\n",
       " 'lyrics',\n",
       " 'hrefhttpwwwjarchivecommedia20071203j02jpg',\n",
       " 'galilee',\n",
       " 'hrefhttpwwwjarchivecommedia20050121dj13jpg',\n",
       " 'withstand',\n",
       " 'skewer',\n",
       " 'merger',\n",
       " '56game',\n",
       " 'releases',\n",
       " 'flamborough',\n",
       " 'senators',\n",
       " 'admirals',\n",
       " 'fallout',\n",
       " 'bridget',\n",
       " 'existence',\n",
       " 'senile',\n",
       " 'lazarus',\n",
       " 'belvedere',\n",
       " 'patentleather',\n",
       " 'candles',\n",
       " 'disappears',\n",
       " 'regime',\n",
       " 'aphids',\n",
       " 'brainchild',\n",
       " 'rigolettos',\n",
       " 'warmblooded',\n",
       " 'tickle',\n",
       " 'coleridge',\n",
       " 'roccasecca',\n",
       " 'tsingtao',\n",
       " 'unruly',\n",
       " 'kamerlingh',\n",
       " 'highest',\n",
       " 'xraying',\n",
       " 'diminuendo',\n",
       " 'garcia',\n",
       " 'northeast',\n",
       " 'pleated',\n",
       " 'veneta',\n",
       " 'idahos',\n",
       " 'durning',\n",
       " 'scotia',\n",
       " 'appreciation',\n",
       " '4winged',\n",
       " 'hrefhttpwwwjarchivecommedia20091123dj30wmvalex',\n",
       " 'longnecked',\n",
       " 'jordans',\n",
       " 'tarpon',\n",
       " 'celebs',\n",
       " 'exotic',\n",
       " 'papago',\n",
       " 'worshippers',\n",
       " 'frampton',\n",
       " 'quelle',\n",
       " 'widest',\n",
       " 'debunked',\n",
       " 'congressional',\n",
       " 'mchales',\n",
       " 'crucify',\n",
       " 'theons',\n",
       " 'colorfully',\n",
       " 'resort',\n",
       " 'genesis',\n",
       " 'forgiven',\n",
       " 'donner',\n",
       " 'overran',\n",
       " 'hamptons',\n",
       " 'aitcheson',\n",
       " 'unchanging',\n",
       " 'geophysical',\n",
       " 'sursson',\n",
       " 'morticia',\n",
       " 'tackling',\n",
       " 'jingdezhen',\n",
       " 'writing',\n",
       " 'jacobitism',\n",
       " 'sharona',\n",
       " 'targetblankwellknown',\n",
       " 'compiled',\n",
       " 'twelfth',\n",
       " 'founder',\n",
       " 'tribes',\n",
       " 'cilicia',\n",
       " 'leoncavallo',\n",
       " 'masonry',\n",
       " 'loverly',\n",
       " 'barbie',\n",
       " 'businessmen',\n",
       " 'matriarch',\n",
       " 'whenever',\n",
       " 'hrefhttpwwwjarchivecommedia20080722dj26wmvsarah',\n",
       " 'marjorie',\n",
       " 'quietly',\n",
       " 'compute',\n",
       " 'fanning',\n",
       " 'reminder',\n",
       " 'religions',\n",
       " 'technique',\n",
       " 'gemological',\n",
       " 'simeon',\n",
       " 'horrible',\n",
       " 'correspondent',\n",
       " 'costume',\n",
       " 'relies',\n",
       " 'abdomen',\n",
       " 'punjabi',\n",
       " 'dorsal',\n",
       " 'oneida',\n",
       " 'hrefhttpwwwjarchivecommedia19981029dj19jpg',\n",
       " 'semiprecious',\n",
       " 'choirboy',\n",
       " 'birmingham',\n",
       " 'veterans',\n",
       " 'justify',\n",
       " 'dostoyevsky',\n",
       " 'hrefhttpwwwjarchivecommedia20030107j23jpg',\n",
       " 'granny',\n",
       " 'tervasaaria',\n",
       " 'insincerity',\n",
       " 'metaphorically',\n",
       " 'galatians',\n",
       " 'skysoaring',\n",
       " 'terror',\n",
       " 'scenes',\n",
       " 'seasoned',\n",
       " 'beasts',\n",
       " 'rayburn',\n",
       " 'toothbrushes',\n",
       " 'dubois',\n",
       " 'hammerin',\n",
       " 'tristram',\n",
       " 'bilthousands',\n",
       " 'geology',\n",
       " 'californication',\n",
       " 'torontos',\n",
       " 'breckinridge',\n",
       " 'tuition',\n",
       " 'hrefhttpwwwjarchivecommedia20050411j29jpg',\n",
       " 'bowieknifed',\n",
       " 'biggers',\n",
       " 'accuse',\n",
       " 'planoconvex',\n",
       " 'examples',\n",
       " 'inserted',\n",
       " 'hrefhttpwwwjarchivecommedia19971110dj28jpg',\n",
       " 'vanishes',\n",
       " 'joneses',\n",
       " 'levant',\n",
       " 'heinlein',\n",
       " 'hrefhttpwwwjarchivecommedia20080723dj03jpg',\n",
       " 'hrefhttpwwwjarchivecommedia20101207j27jpg',\n",
       " 'donelson',\n",
       " 'vicenzos',\n",
       " 'bushel',\n",
       " 'philanthropist',\n",
       " 'memorable',\n",
       " 'sicilian',\n",
       " 'touched',\n",
       " 'revolutionary',\n",
       " 'equestrian',\n",
       " 'sleepy',\n",
       " 'bostonians',\n",
       " 'incredible',\n",
       " 'capitoline',\n",
       " 'givens',\n",
       " 'peeled',\n",
       " 'repaid',\n",
       " 'consumer',\n",
       " 'direction',\n",
       " 'backing',\n",
       " 'amusing',\n",
       " 'packers',\n",
       " 'street',\n",
       " 'criminal',\n",
       " 'stubble',\n",
       " 'nonstop',\n",
       " 'brotherly',\n",
       " 'crawfords',\n",
       " 'interchangeably',\n",
       " 'brigades',\n",
       " 'monumental',\n",
       " 'exaggerated',\n",
       " 'periodic',\n",
       " 'hrefhttpwwwjarchivecommedia20080508j30mp3ishot',\n",
       " 'hoyles',\n",
       " 'knotts',\n",
       " 'florenz',\n",
       " 'junkie',\n",
       " 'huygens',\n",
       " 'enforces',\n",
       " 'sundae',\n",
       " 'gleason',\n",
       " 'holiday',\n",
       " 'fathead',\n",
       " 'phototherapy',\n",
       " 'reputation',\n",
       " 'wanghia',\n",
       " 'kalahari',\n",
       " 'gethsemane',\n",
       " 'dogberts',\n",
       " 'runcible',\n",
       " 'hrefhttpwwwjarchivecommedia20080310j01mp3ive',\n",
       " 'anchored',\n",
       " 'sacrum',\n",
       " 'insertions',\n",
       " 'electrically',\n",
       " 'luxembourg',\n",
       " 'negligence',\n",
       " 'hrefhttpwwwjarchivecommedia20080404j16wmvsarah',\n",
       " 'ranged',\n",
       " 'hrefhttpwwwjarchivecommedia20061019j28jpg',\n",
       " 'alpaca',\n",
       " 'flames',\n",
       " 'professional',\n",
       " 'racquetball',\n",
       " 'regarded',\n",
       " 'marital',\n",
       " 'hrefhttpwwwjarchivecommedia20090211dj14jpg',\n",
       " 'calypso',\n",
       " 'enthusiast',\n",
       " 'edited',\n",
       " 'notredame',\n",
       " 'choyonosekku',\n",
       " 'teenage',\n",
       " 'driver',\n",
       " 'bouligny',\n",
       " 'woolsey',\n",
       " 'tennysons',\n",
       " 'triggers',\n",
       " 'cinder',\n",
       " 'spectators',\n",
       " 'repaired',\n",
       " 'pompey',\n",
       " 'aching',\n",
       " 'quebec',\n",
       " 'entirely',\n",
       " 'arthurian',\n",
       " 'sitting',\n",
       " 'hillary',\n",
       " 'symobol',\n",
       " 'renovated',\n",
       " 'vinland',\n",
       " 'morgans',\n",
       " 'vertebrae',\n",
       " 'sociologists',\n",
       " 'europa',\n",
       " 'exphillie',\n",
       " 'questioned',\n",
       " 'carols',\n",
       " 'canutillo',\n",
       " 'commons',\n",
       " 'endorphins',\n",
       " 'bashing',\n",
       " 'diesel',\n",
       " 'unstable',\n",
       " 'informal',\n",
       " 'discoinacave',\n",
       " 'soaked',\n",
       " 'certainly',\n",
       " 'luhsootoo',\n",
       " 'supine',\n",
       " 'stevens',\n",
       " 'bounty',\n",
       " 'romanov',\n",
       " '12dayold',\n",
       " 'outlook',\n",
       " 'persias',\n",
       " 'joseph',\n",
       " 'indents',\n",
       " 'targetblank1a',\n",
       " 'shishkebabbed',\n",
       " 'kunsthistorisches',\n",
       " 'exceeding',\n",
       " 'krakatoa',\n",
       " 'circulation',\n",
       " 'blutarsky',\n",
       " 'washingtons',\n",
       " 'froggie',\n",
       " 'dancing',\n",
       " 'redtailed',\n",
       " 'solero',\n",
       " 'hardware',\n",
       " 'shagreen',\n",
       " '100foottall',\n",
       " 'worldrenowned',\n",
       " 'litigation',\n",
       " 'timber',\n",
       " 'nibblers',\n",
       " 'majority',\n",
       " 'hrefhttpwwwjarchivecommedia20091124dj11ajpg',\n",
       " 'deceives',\n",
       " 'investor',\n",
       " 'cottages',\n",
       " 'mormonisms',\n",
       " 'drones',\n",
       " 'adjusting',\n",
       " 'hrefhttpwwwjarchivecommedia20080408j26jpg',\n",
       " 'accession',\n",
       " 'pontchartrain',\n",
       " 'hrefhttpwwwjarchivecommedia20060601j04jpg',\n",
       " 'gasping',\n",
       " 'louvre',\n",
       " 'vermont',\n",
       " 'canvas',\n",
       " 'lesson',\n",
       " 'improve',\n",
       " 'cartoon',\n",
       " 'devotions',\n",
       " 'feathered',\n",
       " 'stretches',\n",
       " 'imaginary',\n",
       " 'bibliothecarius',\n",
       " 'sirius',\n",
       " 'undreamed',\n",
       " 'mesopotamia',\n",
       " 'netherworld',\n",
       " 'ulaanbaatar',\n",
       " 'bangles',\n",
       " 'beyonce',\n",
       " 'dating',\n",
       " 'longlost',\n",
       " 'mercury',\n",
       " 'wollstonecraft',\n",
       " 'abductions',\n",
       " 'polyhedron',\n",
       " 'coauthored',\n",
       " 'striking',\n",
       " 'leibniz',\n",
       " 'ricans',\n",
       " 'staple',\n",
       " 'constantine',\n",
       " 'corrupts',\n",
       " 'oddtoed',\n",
       " 'primaries',\n",
       " 'brushes',\n",
       " 'clubbing',\n",
       " 'calistas',\n",
       " 'leadermilitary',\n",
       " 'quartet',\n",
       " 'whitehousegov',\n",
       " 'struensee',\n",
       " 'throbbing',\n",
       " 'gilbert',\n",
       " 'sumerians',\n",
       " 'hrefhttpwwwjarchivecommedia20110505dj21jpg',\n",
       " 'philippines',\n",
       " 'lanner',\n",
       " 'widowed',\n",
       " 'waynes',\n",
       " 'chippendale',\n",
       " 'seminoles',\n",
       " 'jolson',\n",
       " 'lehigh',\n",
       " 'passamaquoddy',\n",
       " 'punica',\n",
       " 'fionas',\n",
       " 'prudhoe',\n",
       " 'affects',\n",
       " 'elisabeth',\n",
       " 'shinkansen',\n",
       " 'nightmaremtvs',\n",
       " 'locomotion',\n",
       " 'littleness',\n",
       " '150yearold',\n",
       " 'butthead',\n",
       " 'hrefhttpwwwjarchivecommedia20071204dj23jpg',\n",
       " 'granada',\n",
       " 'quipped',\n",
       " 'adventure',\n",
       " 'minivan',\n",
       " 'activist',\n",
       " 'alcohol',\n",
       " 'bucket',\n",
       " 'mordabito',\n",
       " 'advertisement',\n",
       " 'sugarcandy',\n",
       " 'stories',\n",
       " 'persistent',\n",
       " 'botanist',\n",
       " 'incompletion',\n",
       " 'hrefhttpwwwjarchivecommedia20080509j24ajpg',\n",
       " 'enterprise',\n",
       " 'thishow',\n",
       " 'lightly',\n",
       " 'franciscan',\n",
       " 'subjects',\n",
       " 'inflatable',\n",
       " 'brainwashed',\n",
       " 'besleeve',\n",
       " 'heavens',\n",
       " 'herbie',\n",
       " 'ability',\n",
       " 'crawly',\n",
       " 'commonwealth',\n",
       " 'observable',\n",
       " 'triumph',\n",
       " 'hrefhttpwwwjarchivecommedia20041020dj17jpg',\n",
       " 'hecate',\n",
       " 'ferris',\n",
       " 'titles',\n",
       " 'catholic',\n",
       " 'hostess',\n",
       " 'alceste',\n",
       " 'operaman',\n",
       " 'intervento',\n",
       " 'cather',\n",
       " 'stacie',\n",
       " 'hundreds',\n",
       " 'chaucer',\n",
       " 'tenochtitlan',\n",
       " 'sweatinducing',\n",
       " 'herselt',\n",
       " 'cornus',\n",
       " 'snoopys',\n",
       " 'macadamia',\n",
       " 'ladies',\n",
       " 'ericsons',\n",
       " 'throne',\n",
       " 'occupies',\n",
       " '5footlong',\n",
       " 'museuma',\n",
       " 'headers',\n",
       " 'singular',\n",
       " 'meanies',\n",
       " 'colonists',\n",
       " 'tolled',\n",
       " 'fortyniners',\n",
       " 'telfair',\n",
       " 'nightmare',\n",
       " 'sports',\n",
       " 'helmeta',\n",
       " 'managers',\n",
       " 'trademark',\n",
       " 'farleys',\n",
       " 'tenderest',\n",
       " 'anthracite',\n",
       " 'favorask',\n",
       " 'families',\n",
       " 'cartographic',\n",
       " 'strolls',\n",
       " 'rowboat',\n",
       " 'instance',\n",
       " 'omelets',\n",
       " 'ribosomal',\n",
       " 'vacancy',\n",
       " 'carlsbad',\n",
       " '525600',\n",
       " 'steven',\n",
       " 'ruthies',\n",
       " 'potential',\n",
       " 'bowribbeting',\n",
       " 'teeming',\n",
       " 'interests',\n",
       " 'sweeney',\n",
       " 'explained',\n",
       " 'izzard',\n",
       " 'ragged',\n",
       " 'sterility',\n",
       " 'spacebullet',\n",
       " 'privately',\n",
       " 'tattered',\n",
       " 'hrefhttpwwwjarchivecommedia20010904j22jpg',\n",
       " 'bullfighting',\n",
       " 'fonteyn',\n",
       " 'participants',\n",
       " 'challenge',\n",
       " 'asleep',\n",
       " 'bookstore',\n",
       " 'ganges',\n",
       " 'crucibles',\n",
       " 'annelids',\n",
       " 'nature',\n",
       " 'longserving',\n",
       " 'newmans',\n",
       " 'opponent',\n",
       " 'ruminant',\n",
       " 'nikita',\n",
       " 'hawkweed',\n",
       " 'cognress',\n",
       " 'targetblankfancy',\n",
       " 'stockwell',\n",
       " 'nichols',\n",
       " 'acclaimed',\n",
       " 'hrefhttpwwwjarchivecommedia20071226dj29jpg',\n",
       " 'stadsholmen',\n",
       " '26year',\n",
       " 'destroyed',\n",
       " 'sanhedrin',\n",
       " '99yearold',\n",
       " 'automatons',\n",
       " 'raquel',\n",
       " 'strumpet',\n",
       " 'odonnell',\n",
       " 'polygonal',\n",
       " 'hrefhttpwwwjarchivecommedia20040706j09wmvthe',\n",
       " 'memphisbased',\n",
       " 'futures',\n",
       " 'godzilla',\n",
       " 'forces',\n",
       " 'parmesan',\n",
       " 'mohawk',\n",
       " 'vernes',\n",
       " 'nebuzaradan',\n",
       " 'spitzer',\n",
       " 'pumpkin',\n",
       " 'hilarious',\n",
       " 'cutthroat',\n",
       " 'software',\n",
       " 'unspeakable',\n",
       " 'serling',\n",
       " 'targetblankseen',\n",
       " 'poodle',\n",
       " 'generation',\n",
       " 'stalin',\n",
       " 'highenergy',\n",
       " 'pastures',\n",
       " 'latitude',\n",
       " 'marconi',\n",
       " 'midday',\n",
       " 'doorposts',\n",
       " 'hilton',\n",
       " 'smoothfronted',\n",
       " 'yangshao',\n",
       " 'amsterdam',\n",
       " 'darned',\n",
       " 'glaring',\n",
       " 'hoarders',\n",
       " 'kristoff',\n",
       " 'strauss',\n",
       " 'shredded',\n",
       " 'sorcery',\n",
       " 'moments',\n",
       " 'fertilizers',\n",
       " 'cordate',\n",
       " 'moratuwa',\n",
       " 'cousins',\n",
       " 'positrons',\n",
       " 'grandcamp',\n",
       " 'identificado',\n",
       " 'unfortunate',\n",
       " 'continents',\n",
       " 'covenant',\n",
       " 'methods',\n",
       " 'hrefhttpwwwjarchivecommedia20040628j10jpg',\n",
       " 'siddim',\n",
       " 'mccartney',\n",
       " 'telescope',\n",
       " 'carrolls',\n",
       " 'bretton',\n",
       " 'victorians',\n",
       " 'posters',\n",
       " 'gravitational',\n",
       " 'yugoslavian',\n",
       " 'covent',\n",
       " 'bariloche',\n",
       " 'chordata',\n",
       " 'dilbert',\n",
       " 'heavyset',\n",
       " 'courageous',\n",
       " 'childlike',\n",
       " 'jablum',\n",
       " 'dublinborn',\n",
       " 'smothered',\n",
       " 'pillars',\n",
       " 'basement',\n",
       " 'bobsleda',\n",
       " 'nizhneangarsk',\n",
       " 'hiding',\n",
       " 'shaking',\n",
       " 'indicates',\n",
       " 'policies',\n",
       " 'clayderman',\n",
       " 'hrefhttpwwwjarchivecommedia20090525dj28jpg',\n",
       " 'discussion',\n",
       " 'etesian',\n",
       " 'cansino',\n",
       " 'hasenohren',\n",
       " 'assumed',\n",
       " 'skinjobs',\n",
       " 'infielder',\n",
       " 'quotes',\n",
       " 'numerals',\n",
       " 'mid1950s',\n",
       " 'everybodys',\n",
       " 'attire',\n",
       " 'partosage',\n",
       " 'colenterates',\n",
       " 'serpentarium',\n",
       " 'exencyclopedia',\n",
       " '50year',\n",
       " 'scottie',\n",
       " 'ringlike',\n",
       " 'herrmann',\n",
       " 'cristobal',\n",
       " 'cultivate',\n",
       " 'thalberg',\n",
       " 'defeating',\n",
       " 'monodon',\n",
       " 'mitterand',\n",
       " 'targetblankshe',\n",
       " 'adopts',\n",
       " 'panther',\n",
       " 'proclaim',\n",
       " 'toward',\n",
       " 'gables',\n",
       " 'cabinda',\n",
       " 'devised',\n",
       " 'saddam',\n",
       " 'crossechecking',\n",
       " 'carlitos',\n",
       " 'speakers',\n",
       " 'hrefhttpwwwjarchivecommedia20091014j06wmvkelly',\n",
       " 'diamond',\n",
       " 'bestselling',\n",
       " 'seedspitting',\n",
       " 'smoked',\n",
       " 'karolyi',\n",
       " 'caddie',\n",
       " 'brotherhoodsisterhood',\n",
       " 'energy',\n",
       " 'schultz',\n",
       " 'qualities',\n",
       " 'archangels',\n",
       " 'wonderland',\n",
       " 'kingsley',\n",
       " 'faerie',\n",
       " 'teamed',\n",
       " 'clooney',\n",
       " 'manchester',\n",
       " 'brecht',\n",
       " 'habsburg',\n",
       " 'sardanapalus',\n",
       " 'guerre',\n",
       " 'hrefhttpwwwjarchivecommedia20080722dj26ajpg',\n",
       " 'reopen',\n",
       " 'england',\n",
       " 'destinations',\n",
       " 'spanakopitta',\n",
       " 'struggle',\n",
       " 'grandmas',\n",
       " 'lodine',\n",
       " 'conversation',\n",
       " 'heptathlon',\n",
       " '20year',\n",
       " 'bainbridge',\n",
       " 'puerco',\n",
       " 'tootsey',\n",
       " 'pickford',\n",
       " 'arithmos',\n",
       " 'jazzman',\n",
       " 'photographic',\n",
       " 'mouths',\n",
       " 'antietam',\n",
       " 'sagans',\n",
       " 'fabriano',\n",
       " 'winery',\n",
       " 'scheme',\n",
       " 'oneswhens',\n",
       " 'hrefhttpwwwjarchivecommedia20050502j01ajpg',\n",
       " 'ushers',\n",
       " 'hrefhttpwwwjarchivecommedia20091221j03jpg',\n",
       " 'hrefhttpwwwjarchivecommedia20060206dj13jpg',\n",
       " 'smashed',\n",
       " 'transport',\n",
       " 'introduction',\n",
       " 'armynavy',\n",
       " 'oneills',\n",
       " 'ensured',\n",
       " 'hrefhttpwwwjarchivecommedia20110330dj26jpg',\n",
       " 'luteinizing',\n",
       " 'listed',\n",
       " 'spacecraft',\n",
       " 'unwanted',\n",
       " 'hotshot',\n",
       " 'apprenticeia',\n",
       " 'accompanying',\n",
       " 'montmorency',\n",
       " 'incisors',\n",
       " 'precivil',\n",
       " 'recounted',\n",
       " 'conducted',\n",
       " 'september',\n",
       " 'relied',\n",
       " 'sopranos',\n",
       " 'hrefhttpwwwjarchivecommedia20080227dj27jpg',\n",
       " 'chungyang',\n",
       " 'swinging',\n",
       " 'indulging',\n",
       " 'tahiti',\n",
       " 'christians',\n",
       " 'florence',\n",
       " 'cajuns',\n",
       " 'guiteau',\n",
       " 'nonmuslims',\n",
       " 'oldest',\n",
       " 'punched',\n",
       " 'hrefhttpwwwjarchivecommedia20060426j07mp3thisa',\n",
       " 'garment',\n",
       " 'fertig',\n",
       " 'francois',\n",
       " 'supported',\n",
       " 'manila',\n",
       " 'regents',\n",
       " 'implying',\n",
       " 'convention',\n",
       " 'limited',\n",
       " 'chouans',\n",
       " 'corresponds',\n",
       " 'originally',\n",
       " 'annapolis',\n",
       " 'transcanada',\n",
       " 'determining',\n",
       " 'pfefferminz',\n",
       " 'andrea',\n",
       " 'listings',\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms_used_unique = list(set(terms_used))\n",
    "terms_used_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value analysis\n",
    "\n",
    "There is close to 70% overlap between the words in the new questions and the words in the old questions. Since we are not looking into any phrases or exact same questions, it is tough to decide if this is significant or not. But the percentage is big enough that it is worth doing futher analysis\n",
    "\n",
    "We want to restirct our analysis to high value questions so that we can get  more money in the game show. We will designate any amount more $800 as high value amount. Once we have thid categorization, we can check which of our words/terms correspond to high value questions using chi-squared test. \n",
    "\n",
    "FIrst lets narrow down our questions into two catgories\n",
    "\n",
    "   - Low value -- Any row where Value is less than 800.\n",
    "   - High value -- Any row where Value is greater than 800."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_value(row):\n",
    "    value = 0\n",
    "    if row[\"clean_value\"] > 800:\n",
    "        value = 1\n",
    "    return value\n",
    "\n",
    "jeopardy[\"high_value\"] = jeopardy.apply(determine_value, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we will be able to loop through each of the terms in **`terms_used`**, and:\n",
    "\n",
    "   - Find the number of low value questions the word occurs in.\n",
    "   - Find the number of high value questions the word occurs in.\n",
    "   - Find the percentage of questions the word occurs in.\n",
    "   - Based on the percentage of questions the word occurs in, find expected counts.\n",
    "   - Compute the chi squared value based on the expected counts and the observed counts for high and low value questions.\n",
    "   \n",
    "We can then find the words with the biggest differences in usage between high and low value questions, by selecting the words with the highest associated chi-squared values. Doing this for all of the words would take a very long time, so we'll just do it for a small sample now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_usage(jeopardy, term):\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for i, row in jeopardy.iterrows():\n",
    "        if term in row[\"clean_question\"].split(\" \"):\n",
    "            if row[\"high_value\"] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return high_count, low_count\n",
    "\n",
    "\n",
    "def find_observed(jeopardy, comparison_terms):\n",
    "    print(comparison_terms)\n",
    "    observed = []\n",
    "    for term in comparison_terms:\n",
    "        observed.append(count_usage(jeopardy, term))\n",
    "    return observed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-squared and p values\n",
    "\n",
    "Now that we have found the observed counts for a few terms, we can compute the expected counts and the chi-squared value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_chi_squared(jeopardy, observed):\n",
    "    from scipy.stats import chisquare\n",
    "    import numpy as np\n",
    "    high_value_count = jeopardy[jeopardy[\"high_value\"] == 1].shape[0]\n",
    "    low_value_count = jeopardy[jeopardy[\"high_value\"] == 0].shape[0]\n",
    "\n",
    "    chi_squared = []\n",
    "    for obs in observed:\n",
    "        total = sum(obs)\n",
    "        total_prop = total / jeopardy.shape[0]\n",
    "        high_value_exp = total_prop * high_value_count\n",
    "        low_value_exp = total_prop * low_value_count\n",
    "\n",
    "        obs = np.array([obs[0], obs[1]])\n",
    "        exp = np.array([high_value_exp, low_value_exp])\n",
    "        chi_squared.append(chisquare(obs, exp))\n",
    "\n",
    "    return chi_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_print_chi_squared(jeopardy, terms):\n",
    "    observed = find_observed(jeopardy, terms)\n",
    "\n",
    "    # Now that we have found the observed counts for a few terms,\n",
    "    # we can compute the expected counts and the chi-squared value.\n",
    "    chi_squared = calculate_chi_squared(jeopardy, observed)\n",
    "    for chi_sq in chi_squared:\n",
    "        print(\"statistic = {0:.2f} p value = {1:.2f}%\".format(\n",
    "            chi_sq[0], chi_sq[1]*100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hrefhttpwwwjarchivecommedia20110718j10jpg', 'consistent', 'leinart', 'evertuned', 'shopkeepers', 'impoverished', 'csonkaa', 'easing', 'mercurys', 'typical']\n"
     ]
    }
   ],
   "source": [
    "words_to_check = 10\n",
    "find_and_print_chi_squared(jeopardy, terms_used_unique[:words_to_check] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-squared results\n",
    "\n",
    "None of the terms had a significant difference in usage between high value and low value rows. Additionally, the frequencies were all lower than 5, so the chi-squared test isn't as valid. It would be better to run this test with only terms that have higher frequencies.\n",
    "\n",
    "### Chi-squared test on high frequency words\n",
    "\n",
    "Lets create the frequency table and run the chi squared test only for the terms that have occured atleast 100 times or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_used_freq = pd.Series(sorted(terms_used)).value_counts()\n",
    "terms_used_100_times_or_more = terms_used_freq[terms_used_freq > 100]\n",
    "terms_used_100_times_or_more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_and_print_chi_squared(jeopardy, terms_used_100_times_or_more.index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi squared for high frequency word results\n",
    "\n",
    "Again the p values are very high and most of them are well above 5% which is our theoritial limit for determining if the relationship exits are the results are just randon. So we will have to abaondon our analysis and accept null hypothesis\n",
    "\n",
    "## Conculsion\n",
    "\n",
    "We reject the alternate hypothesis and accept the null hypothesis. Any observed relationship between questions asked in the newer episode against those asked in the older episodes are just random in nature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
