{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Hacker news posts - When can one get the best response\n",
    "\n",
    "This project explores various kinds of Hacker news posts. We will analyze the posts and come up with some meaningful insights. Since the data in the dataset is huge, we will be restricting ourselves to analyzing user submitted posts which begin with `Ask HN` or `Show HN`\n",
    "\n",
    "`Ask HN` are posts submitted by the users asking some advise or tips from `Hacker News` community. For eg\n",
    "\n",
    ">`\n",
    "Ask HN: How to improve my personal website?\n",
    "Ask HN: Am I the only one outraged by Twitter shutting down share counts?\n",
    "Ask HN: Aby recent changes to CSS that broke mobile?\n",
    "`\n",
    "\n",
    "Similarly `Show HN`is used by uses to showcase some project, product, intersting articles, etc Some examples include \n",
    "\n",
    ">`\n",
    "Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform'\n",
    "Show HN: Something pointless I made\n",
    "Show HN: Shanhu.io, a programming playground powered by e8vm\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our general approach would be to \n",
    "\n",
    "1. Separate header from rest of the data\n",
    "2. Create separate `Ask HN`, `Show HN` posts from other posts\n",
    "3. Calculate total number of comments and average comments per post for both `Ask HN` and `Show HN`\n",
    "4. Dig deeper into either one of them based on which category gets more comments on averate\n",
    "\n",
    "\n",
    "## 1. Separate header from rest of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "\n",
    "file_open = open(\"hacker_news.csv\")\n",
    "hn_reader = reader(file_open)\n",
    "hn = list(hn_reader)\n",
    "\n",
    "print(hn[:5], sep=\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an header in this dataset. We need to remove the header and so that we can easily loop through the dateset for our various analysis. WE don't want to lose the header so we will remove it and assign it to a separate variable alled `headers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']\n",
      "\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']\n",
      "\n",
      "['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']\n"
     ]
    }
   ],
   "source": [
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "print(*hn[:5], sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create separate `Ask HN`, `Show HN` posts from other posts\n",
    "\n",
    "Since we are only concentrating on `Ask HN` or `Show HN` messages we need to isolate them by looking at the title. Python provides us string methods like startswith() which can check if a string starts with a given string. We will use this method to check to if our titles start with `Ask HN` and `Show HN` and add them to a separate list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show HN count = 1162\n",
      "['10627194', 'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform', 'https://iot.seeed.cc', '26', '22', 'kfihihc', '11/25/2015 14:03']\n",
      "\n",
      "['10646440', 'Show HN: Something pointless I made', 'http://dn.ht/picklecat/', '747', '102', 'dhotson', '11/29/2015 22:46']\n",
      "\n",
      "Ask HN count = 1744\n",
      "['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55']\n",
      "\n",
      "['10610020', 'Ask HN: Am I the only one outraged by Twitter shutting down share counts?', '', '28', '29', 'tkfx', '11/22/2015 13:43']\n",
      "\n",
      "Other posts count = 17194\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for post in hn:\n",
    "    title = post[1]\n",
    "    \n",
    "    if title[:7].lower().startswith(\"show hn\") :\n",
    "        show_posts.append(post)\n",
    "    elif title[:7].lower().startswith(\"ask hn\") :\n",
    "        ask_posts.append(post)\n",
    "    else:\n",
    "        other_posts.append(post)\n",
    "\n",
    "\n",
    "print(\"Show HN count = {}\".format(len(show_posts)))\n",
    "print(*show_posts[:2], sep=\"\\n\\n\")\n",
    "print()\n",
    "\n",
    "print(\"Ask HN count = {}\".format(len(ask_posts)))\n",
    "print(*ask_posts[:2], sep=\"\\n\\n\")\n",
    "print()\n",
    "\n",
    "print(\"Other posts count = {}\".format(len(other_posts)))\n",
    "print(*other_posts[:2], sep=\"\\n\\n\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate total number of comments and average comments per post for both `Ask HN` and `Show HN`\n",
    "\n",
    "Now that we have separate lists containing Ask and Show posts, lets go ahead calculate the total comments and average comments each of these posts attracted. Our bigger goal is to check which one of `Show HN and Ask HN` post attract more comments on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744 'Ask HN:' posts have recieved total 24483 comments. Average comments per post is 14.04\n",
      "1162 'Show HN:' posts have recieved total 11988 comments. Average comments per post is 10.32\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "\n",
    "for ask_post in ask_posts:\n",
    "    total_ask_comments += int(ask_post[4])\n",
    "\n",
    "avg_ask_comments = total_ask_comments/len(ask_posts)\n",
    "print(\"{} 'Ask HN:' posts have recieved total {} comments. Average comments per post is {:.2f}\".format(len(ask_posts), total_ask_comments, avg_ask_comments))\n",
    "\n",
    "\n",
    "total_show_comments = 0\n",
    "\n",
    "for show_post in show_posts:\n",
    "    total_show_comments += int(show_post[4])\n",
    "\n",
    "avg_show_comments = total_show_comments/len(show_posts)\n",
    "print(\"{} 'Show HN:' posts have recieved total {} comments. Average comments per post is {:.2f}\".format(len(show_posts), total_show_comments, avg_show_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Show HN` comments have received an average 10 comments per post while `Ask HN`posts have received nearly 35% more comments per post with average comments being around 14.04. This shows that clearly the Hacker News community is more engaged when users ask them questions then merely point out at intersting projects, products or topics. \n",
    "\n",
    "## 4. Dig deeper into `Ask HN`  posts and find out what time of the day attracts most comments\n",
    "\n",
    "Consdiering that `Ask HN` posts attrack the most comments, we will concentrate on them for our future analysis, We want to find out the time of the day when the ask posts attrack the most number of comments.To get this insight we need to first create a frequency table which lists hour of the day and the number of posts in that hour. We will do this using datetime.strptime() constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('11', 58) ('18', 109) ('05', 46) ('13', 85) ('19', 110) ('03', 54) ('08', 48) ('04', 47) ('21', 109) ('09', 45) ('22', 71) ('20', 80) ('06', 44) ('07', 34) ('23', 68) ('17', 100) ('01', 60) ('02', 58) ('12', 73) ('00', 55) ('10', 59) ('16', 108) ('15', 116) ('14', 107)\n",
      "\n",
      "\n",
      "('11', 641) ('18', 1439) ('05', 464) ('13', 1253) ('19', 1188) ('03', 421) ('08', 492) ('04', 337) ('21', 1745) ('09', 251) ('22', 479) ('20', 1722) ('06', 397) ('07', 267) ('23', 543) ('17', 1146) ('01', 683) ('02', 1381) ('12', 687) ('00', 447) ('10', 793) ('16', 1814) ('15', 4477) ('14', 1416)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for ask_post in ask_posts:\n",
    "    date_str = ask_post[6]\n",
    "    comment_count = int(ask_post[4])\n",
    "    date = dt.datetime.strptime(date_str, \"%m/%d/%Y %H:%M\")\n",
    "    hour = date.strftime(\"%H\")\n",
    "    \n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = comment_count\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += comment_count\n",
    "   \n",
    "    \n",
    "print(*counts_by_hour.items())\n",
    "print(\"\\n\")\n",
    "                                \n",
    "print(*comments_by_hour.items())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the number of posts and total number of comments for any given hour of the day we can go ahead and calculate average number of comments in a given hour. We will\n",
    "\n",
    "1. First create a list of list containing first element as average comments in the hour and the second element is the hour itself\n",
    "2. We will sort this list in decending order to get the hour with maximum average to come on top\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11.051724137931034, '11'] [13.20183486238532, '18'] [10.08695652173913, '05'] [14.741176470588234, '13'] [10.8, '19'] [7.796296296296297, '03'] [10.25, '08'] [7.170212765957447, '04'] [16.009174311926607, '21'] [5.5777777777777775, '09'] [6.746478873239437, '22'] [21.525, '20'] [9.022727272727273, '06'] [7.852941176470588, '07'] [7.985294117647059, '23'] [11.46, '17'] [11.383333333333333, '01'] [23.810344827586206, '02'] [9.41095890410959, '12'] [8.127272727272727, '00'] [13.440677966101696, '10'] [16.796296296296298, '16'] [38.5948275862069, '15'] [13.233644859813085, '14']\n",
      "\n",
      "\n",
      "[38.5948275862069, '15'] [23.810344827586206, '02'] [21.525, '20'] [16.796296296296298, '16'] [16.009174311926607, '21'] [14.741176470588234, '13'] [13.440677966101696, '10'] [13.233644859813085, '14'] [13.20183486238532, '18'] [11.46, '17'] [11.383333333333333, '01'] [11.051724137931034, '11'] [10.8, '19'] [10.25, '08'] [10.08695652173913, '05'] [9.41095890410959, '12'] [9.022727272727273, '06'] [8.127272727272727, '00'] [7.985294117647059, '23'] [7.852941176470588, '07'] [7.796296296296297, '03'] [7.170212765957447, '04'] [6.746478873239437, '22'] [5.5777777777777775, '09']\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for hour in counts_by_hour:\n",
    "    swap_avg_by_hour.append([comments_by_hour[hour]/counts_by_hour[hour], hour])\n",
    "\n",
    "print()\n",
    "print(*swap_avg_by_hour)\n",
    "print()\n",
    "print()\n",
    "#sort in decending order\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse= True)\n",
    "print(*sorted_swap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Lets print the top five hours in the readable format\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n",
      "13:00: 14.74 average comments per post\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "\n",
    "def formatstring(my_list):\n",
    "    date = dt.datetime.strptime(my_list[1], \"%H\")\n",
    "    hour = date.strftime(\"%H:%M\")\n",
    "    return \"{}: {:.2f} average comments per post\".format(hour, my_list[0])\n",
    "\n",
    "for item in sorted_swap[:6]:\n",
    "    print( formatstring(item))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "As can be seen from the above analysis the best times to post \"Ask HN\" on Hacker News are 15:00, 02:00 and 20:00 hours. They all get 20+ comments on average and those around 15:00 tend to get 38+ comments which is 60% better than the next best hour which is at 02:00 AM. \n",
    "\n",
    "Hours 16:00, 21:00 and 13:00 also tend to bring fairly high number of comments \n",
    "\n",
    "We hope our analysis helps you to find the best time to ask Hacker news community anything you have been itching to ask "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
